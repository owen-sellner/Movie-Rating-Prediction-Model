# -*- coding: utf-8 -*-
"""V4 MSCI 446 - Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dTvPRasQ169MHVYO_z0v3RJBPgUhvgfj

# Group 1 Project

## Group 1 Members
* Gabrielle Tang (20883214)
* Vyomesh Iyenger (20884898)
* Owen Sellner (20915011)
* Edward Ho (20890175)

# Project Report

Link to Report (Google Docs): https://docs.google.com/document/d/1zwvE7PnCdwDTlosAimD4cNDh_RRYeVLmlw9UGboMjS4/edit?usp=sharing

# Uploading Dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# import libraries 
import pandas as pd 
import numpy as np 
import seaborn as sns
import matplotlib.pyplot as plt

import sklearn
from sklearn.cluster import KMeans
import sklearn.metrics as sm
from sklearn import datasets
from sklearn import tree, linear_model, ensemble
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import KFold, GridSearchCV, cross_validate, train_test_split, StratifiedKFold, cross_val_score
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.preprocessing import OneHotEncoder
from sklearn.naive_bayes import MultinomialNB

import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

# upload dataset file
from google.colab import files
uploaded = files.upload()

# import data
import io
data = io.BytesIO(uploaded['movies.csv'])

# load as a data frame
df = pd.read_csv('movies.csv') 
df

"""# Data Overview"""

df.dtypes

df.info()

plot = sns.histplot(data=df, x="score")
plot.set(xlabel='score')
plt.show()

sns.set(rc={"figure.figsize":(20, 4)})
sns.histplot(data=df, x="genre")
plt.show()

"""# Data Cleaning

## Binning Numeric Values
"""

# Seperate score values into bins where each bin has movies with score higher than the 
# values listed in the arrays i.e. bin 1 has scores higher than 0 but lower than 5
bins = np.array([0.0, 5.0, 6.0, 7.0, 8.0, 9.0])
df["new_score_bin"] = np.digitize(df["score"], bins)

df["new_score_bin"].value_counts()

"""## Removing Unnecessary Columns and Instances"""

# Splitting released column into release date and release country
df[['release date', 'release_country']] = df["released"].apply(lambda x: pd.Series(str(x).split("(")))
df["release_country"] = df["release_country"].str[:-1]
df["release_country"].value_counts()

# Keeping only english-speaking countries
df = df.loc[(df["release_country"] == 'United States') | (df["release_country"] == 'United Kingdom') | (df["release_country"] == 'Australia')]
df["release_country"].value_counts()

# Removing unnecessary genres
df = df.loc[(df["genre"] == 'Drama') | (df["genre"] == 'Adventure') | (df["genre"] == 'Action') | (df["genre"] == 'Comedy') | (df["genre"] == 'Horror') | (df["genre"] == 'Biography') | (df["genre"] == 'Crime') | (df["genre"] == 'Fantasy') | (df["genre"] == 'Animation')]
df["genre"].value_counts()

# Removing unnecessary columns
df = df.drop(columns=['rating', 'released','release date','votes', 'country', 'writer', 'gross', 'company', 'budget', 'runtime', 'name', 'director'])
df

"""## Remove Null Rows"""

# Remove null genre
df = df.loc[df["genre"].notnull()]

# Remove score
df = df.loc[df["score"].notnull()]

"""# Genre Cluster Dataset"""

one_hot = pd.get_dummies(df['genre'])
# Drop unecessary original columns
genre_df = df.drop(["genre", "year", "score", "new_score_bin","release_country"], axis = 1)
# Join the encoded df
genre_df = genre_df.join(one_hot)
# Group by actor
genre_df = genre_df.groupby(['star'], axis=0, as_index=True).sum()
genre_df

"""## Find optimal K value for clustering"""

#create list to hold SSE values for each k
rss = []
for k in range(1, 514):
    kmeans = KMeans(n_clusters=k, init="random", n_init=10, random_state=42)
    kmeans.fit(genre_df)
    rss.append(kmeans.inertia_)

#visualize results
plt.plot(range(1, 514), rss)
plt.xticks(range(1, 514))
plt.xlabel("Number of Clusters")
plt.ylabel("RSS")
plt.show()

#visualize results
plt.figure(figsize=(30,30))
plt.xlim(right=50)
plt.plot(range(1, 514), rss)
plt.xticks(range(1, 50))
plt.xlabel("Number of Clusters")
plt.ylabel("RSS")
plt.show()

"""## Clustering using optimal K value"""

# since the elbow on the graph is at K=12 that is the value that will be used for clustering

kmeans = KMeans(init="random", n_clusters=12, n_init=10, random_state=1)

#fit k-means algorithm to data
kmeans.fit(genre_df)

# apply cluster labels to the dataset

genre_df['cluster'] = kmeans.labels_

genre_df

# histogram of clusters

plot = sns.histplot(data=genre_df, x="cluster")
plot.set(xlabel='clusters')
plt.show()

# number of occurances in each cluster

genre_df["cluster"].value_counts()

genre_df.loc[genre_df["cluster"] == 8]

"""## Apply clustering to Dataset

"""

merge_df = genre_df[["cluster"]].copy()
#merge og data with new column for actor clusters
clustered_df = pd.merge(df, merge_df, how ='inner', on ='star')
clustered_df.sort_values(by =['score'])

"""# One-Hot Encoding Categorical Features"""

#getting count of unique values in each column
for x in clustered_df.columns:
  print(x, ':', len(clustered_df[x].unique()))

clustered_df.genre.value_counts().sort_values(ascending=False).head(2)

# change data type to string in order to one hot encode the non-ordinal numeric features
clustered_df['cluster']= clustered_df['cluster'].map(str)
datatypes = clustered_df.dtypes
datatypes

#lists created for one-hot encoding
genres = [x for x in clustered_df.genre.value_counts().sort_values(ascending=False).head(9).index]
countries = [x for x in clustered_df.release_country.value_counts().sort_values(ascending=False).head(3).index]
clusters = [x for x in clustered_df.cluster.value_counts().sort_values(ascending=False).head(12).index]

clusters

#saving a copy of dataframe
df = clustered_df 

# make binary of labels for genre, release country, cluster, new score bin
for label in genres:
  clustered_df["genre: "+label] = np.where(clustered_df['genre']==label,1,0)

for label in countries:
  clustered_df["country: "+label] = np.where(clustered_df['release_country']==label,1,0)

for label in clusters:
 clustered_df["cluster: "+label] = np.where(clustered_df['cluster']==label,1,0)

clustered_df = df.drop(['genre', 'score', 'star', 'release_country', 'cluster'], axis =1)
clustered_df

"""# Decision Tree"""

tree.d = DecisionTreeClassifier(min_samples_split=100, criterion='entropy', 
                             max_depth=7)

"""# Naive Bayes"""

clf = MultinomialNB(force_alpha=True)

"""# Visualization of Results and Accuracy Evaluation

## Decision Tree Evaluation

K Fold Cross Validation
"""

feature_names=['year', 'genre: Comedy', 'genre: Action', 'genre: Drama', 'genre: Crime', 'genre: Adventure', 'genre: Biography', 'genre: Animation',
               'genre: Horror', 'genre: Fantasy', 'country: United States', 'country: United Kingdom', 'country: Australia', 
               'cluster: 0', 'cluster: 1', 'cluster: 2', 'cluster: 3', 'cluster: 4', 'cluster: 5', 'cluster: 6', 'cluster: 7', 'cluster: 8',
               'cluster: 9', 'cluster: 10', 'cluster: 11']

y = clustered_df["new_score_bin"]

X = clustered_df.filter(regex='^((?!new_score_bin).)*$', axis=1)

kf =KFold(n_splits=10, shuffle=True, random_state=42)

cnt = 1
for train_index, test_index in kf.split(X, y):
   print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')
   cnt += 1

def rmse_tree(score):
    rmse_tree = np.sqrt(-score)
    print(f'rmse= {"{:.2f}".format(rmse_tree)}')

#GETTING RMSE FROM K FOLD VALIDATION
#code adapted from:
#K Fold Cross Validation
#Author: Satish Gunjal
#https://satishgunjal.com/kfold/
score_tree = cross_val_score(tree.d, X, y, cv=kf, scoring="neg_mean_squared_error")

print(f'Scores for each fold: {score_tree}')
rmse_tree(score_tree.mean())

X_train, X_test, y_train, y_test = train_test_split(X, # X 
                                                    y,         # y
                                                    test_size=0.10,      
                                                    random_state = 42)    # consistent split

#Running tree for visualization
tree.d.fit(X_train,y_train)

import imageio,io
import pydotplus

# write function to plot the decision tree
def show_tree(tree, features, path):
  # make file stream to read/write
  f = io.StringIO()
  # export the graph into dot format and save it to the io stream
  export_graphviz(tree, out_file=f, feature_names=feature_names, class_names=['1', '2', '3', '4', '5', '6'],
                  filled=True, rounded=True) # for nicer visualization
  # read the dot data and trnasform it into a png, then save it to path
  pydotplus.graph_from_dot_data(f.getvalue()).write_png(path)
  # read the png image saved at path
  img = imageio.imread(path)
  # plot the png image in the notebook
  plt.rcParams['figure.figsize'] = (20,20)
  plt.imshow(img)

# plot the decision tree
show_tree(tree.d, feature_names,'decision_tree')

y_pred = tree.d.predict(X_test)
from sklearn.metrics import accuracy_score

# get the accurancy
accuracy  = accuracy_score(y_test,y_pred)
print("Accuracy using Decision Tree: ", accuracy*100)

print("\nPredicted values:")
print(y_pred)

"""Confusion Matrix"""

## import 
from sklearn.metrics import confusion_matrix
## create matrix
confusion_matrix(y_test, y_pred, labels=[1, 2, 3, 4, 5, 6])

"""## Naive Bayes Evaluation"""

# Accuracy of a Gaussian Naive Bayes
from sklearn.naive_bayes import GaussianNB
algorithm = GaussianNB(priors=None, var_smoothing=1e-9)

algorithm.fit(X, y)

print('The Gaussian Model Has Achieved %.2f Percent Accuracy'%(algorithm.score(X, y)*100))

# Gaussian Naive Bayes has very low accuracy, in order to improve this we will try Multinomial Naive Bayes

# Accuracy of a Multionomial Naive Bayes
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB(force_alpha=True)

clf.fit(X, y)
print('The Multinomial Model Has Achieved %.2f Percent Accuracy'%(clf.score(X, y)*100))

# testing if model outputs value
print("\nPredicted Value:")
print(clf.predict(X[2:3])[0])

# K-Folds Cross Validation
kf_bayes = KFold(n_splits=10, shuffle = True, random_state =42)

cnt = 1
for train_index, test_index in kf_bayes.split(X,y):
   print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')
   cnt += 1

def rmse_bayes(score_bayes):
  rmse_bayes = np.sqrt(-score_bayes)
  print(f'rmse= {"{:.2f}".format(rmse_bayes)}')

score_bayes = cross_val_score(clf, X, y, cv=kf, scoring="neg_mean_squared_error")
print(f'Scores for each fold: {score_bayes}')
rmse_bayes(score_bayes.mean())

X_train_bayes, X_test_bayes, y_train_bayes, y_test_bayes = train_test_split(X, # X 
                                                    y,         # y
                                                    test_size=0.10,      
                                                    random_state = 42)    # consistent split

y_pred_bayes = clf.predict(X_test_bayes)

"""Confusion Matrix"""

# create matrix
confusion_matrix(y_test_bayes, y_pred_bayes, labels=[1, 2, 3, 4, 5, 6])

"""#User Input

## Getting user input
"""

# Accepts user input and assigns it to variables
print("Movie Information:\n")
print("What year was the movie released?")
user_movie_year = int(input())
print("What genre is the movie? (Action/Adventure/Animation/Biography/Comedy/Crime/Drama/Fantasy/Horror)")
user_movie_genre = input()
print("What country has the movie been released in? (Australia/United Kingdom/United States)")
user_movie_country = input()

print("\nLead Actor Information:\n")
print("How many Action movies has the actor been in?")
user_actor_action = input()
print("How many Adventure movies has the actor been in?")
user_actor_adventure = input()
print("How many Animation movies has the actor been in?")
user_actor_animation = input()
print("How many Biography movies has the actor been in?")
user_actor_biography = input()
print("How many Comedy movies has the actor been in?")
user_actor_comedy = input()
print("How many Crime movies has the actor been in?")
user_actor_crime = input()
print("How many Drama movies has the actor been in?")
user_actor_drama = input()
print("How many Fantasy movies has the actor been in?")
user_actor_fantasy = input()
print("How many Horror movies has the actor been in?")
user_actor_horror = input()

"""## Clustering user input"""

# Drop "cluster" column
genre_df = genre_df.drop("cluster", axis=1, errors='ignore')

# Append input information to dataframe
temp_df = pd.DataFrame([[user_actor_action, user_actor_adventure, user_actor_animation, user_actor_biography, user_actor_comedy, user_actor_crime, user_actor_drama, user_actor_fantasy, user_actor_horror]], 
                       columns=["Action", "Adventure", "Animation", "Biography", "Comedy", "Crime", "Drama", "Fantasy", "Horror"], index=["user_input"])

# Added the user values to the genre dataframe
if ("user_input" not in genre_df.index):
    genre_df = pd.concat([genre_df, temp_df])
else:
  genre_df = genre_df.drop(index = "user_input")
  genre_df = pd.concat([genre_df, temp_df])

# Apply clustering
kmeans = KMeans(init="random", n_clusters=12, n_init=10, random_state=1)

kmeans.fit(genre_df)

genre_df['cluster'] = kmeans.labels_

# Get information about user cluster
clustered_actor_df = genre_df.loc["user_input"]

"""## Prepare user input data"""

# Create of copy of the inputed actor information
user_df = clustered_actor_df.copy()

# Add columns for movie data
user_df["year"] = user_movie_year
user_df["genre"] = user_movie_genre
user_df["release_country"] = user_movie_country

# Convert "cluster" to a string type
user_df["cluster"] = user_df["cluster"].astype(str) 

# Create lists for one-hot encoding loops
genresList = ['Comedy', 'Action', 'Drama', 'Crime', 'Adventure', 'Biography', 'Animation', 'Horror', 'Fantasy']
countriesList = ['United States', 'United Kingdom', 'Australia']
clustersList = ["4", "2", "3", "1", "0", "8", "6", "5", "7", "11", "10", "9"]

# One-Hot Encode the categories
for label in genres:
  user_df["genre: "+label] = np.where(user_df['genre']==label,1,0).sum()

for label in countries:
  user_df["country: "+label] = np.where(user_df['release_country']==label,1,0).sum()

for label in clusters:
 user_df["cluster: "+label] = np.where(user_df['cluster'].astype(str)==label,1,0).sum()

# Drop number of movies in each genre
user_df = user_df.drop(['Comedy', 'Action', 'Drama', 'Crime', 'Adventure', 'Biography', 'Animation', 'Horror', 'Fantasy'])
# Drop unused values from the array
user_df = user_df.drop(['genre', 'release_country', 'cluster'])

user_df

# Convert to dataframe
user_df = user_df.to_frame()

# Transpose rows to columns
user_df = user_df.transpose()
user_df

"""# User Input Prediction

## Predict result using Decision Tree
"""

# Using decision tree and the user input predict the expected audience score 
result_pred = tree.d.predict(user_df)

ratingRanges = ["0%-49%", "50%-59%", "60%-69%", "70%-79%", "80%-89%", "90%-100%"]

print("Predicted Rating Range: " + ratingRanges[result_pred[0]-1])

"""## Predict Result Using Naive Bayes"""

#clf = MultinomialNB(force_alpha=True)
y = clustered_df["new_score_bin"]
X = clustered_df.filter(regex='^((?!new_score_bin).)*$', axis=1)
clf.fit(X, y)
user_df
# print(clf.predict(user_df.filter(regex='^((?!new_score_bin).)*$', axis=1)))
result_predNB = clf.predict(user_df)
print ("Predicted Rating Range: " + ratingRanges[result_predNB[0]-1])